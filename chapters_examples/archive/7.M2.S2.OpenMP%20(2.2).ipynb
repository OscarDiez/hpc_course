{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ijCS7T0wd6BM"
   },
   "source": [
    "# Exercise 7.1: Introduction to OpenMP\n",
    "\n",
    "OpenMP (Open Multi-Processing) is a powerful API designed for parallel programming in shared-memory environments. This exercise will introduce you to the basics of OpenMP, including how to use OpenMP directives to parallelize loops and how to manage thread parallelism.\n",
    "\n",
    "## 7.1.1 Overview of OpenMP\n",
    "\n",
    "### 7.1.1.1 Definition and Purpose of OpenMP\n",
    "OpenMP provides a simple and flexible interface for developing parallel applications by using compiler directives, runtime library routines, and environment variables. It allows developers to parallelize existing serial code incrementally, making it easier to transition from sequential to parallel programming.\n",
    "\n",
    "### 7.1.1.2 Historical Context and Development\n",
    "OpenMP was first introduced in 1997 and has since evolved with support for task-based parallelism, accelerator directives, and memory management improvements, making it a relevant tool in modern HPC environments.\n",
    "\n",
    "### 7.1.1.3 Applicability in Modern HPC Environments\n",
    "OpenMP is widely applicable in modern HPC due to its ability to leverage multicore architectures efficiently. It is used in scientific simulations, data analysis, and real-time processing.\n",
    "\n",
    "## 7.1.2 Key Features of OpenMP\n",
    "\n",
    "### 7.1.2.1 Simple and Flexible Parallel Programming Model\n",
    "OpenMP simplifies parallel programming by allowing developers to parallelize loops with minimal code changes. For example, using the `#pragma omp parallel for` directive to parallelize a loop.\n",
    "\n",
    "### 7.1.2.2 Support for C, C++, and Fortran\n",
    "OpenMP supports multiple programming languages, including C, C++, and Fortran, which broadens its applicability across various scientific and engineering domains.\n",
    "\n",
    "### 7.1.2.3 Portable Across Different Shared-Memory Architectures\n",
    "OpenMP is portable across various shared-memory architectures, ensuring that parallel code can run efficiently on different systems without modification.\n",
    "\n",
    "## 7.1.3 Installation and Setup of OpenMP\n",
    "\n",
    "### 7.1.3.1 Installing OpenMP on Various Platforms\n",
    "- **Linux:** Use GCC with the `-fopenmp` flag to compile OpenMP programs.\n",
    "- **Windows:** Use MinGW or Visual Studio to enable OpenMP support.\n",
    "- **MacOS:** Use Homebrew to install GCC for OpenMP support.\n",
    "\n",
    "### 7.1.3.2 Compiler Support for OpenMP\n",
    "OpenMP is supported by GCC, Clang, and Intel Compilers, each providing robust support for parallel programming.\n",
    "\n",
    "## 7.1.3.3 Thread Parallelism\n",
    "Thread parallelism in OpenMP divides a task into smaller sub-tasks that can be executed by multiple threads simultaneously. This approach leverages multicore processors for efficient parallel execution.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1145,
     "status": "ok",
     "timestamp": 1725773187134,
     "user": {
      "displayName": "Oscar Diez",
      "userId": "15296249123884043247"
     },
     "user_tz": -120
    },
    "id": "KfPGboFwdgVT",
    "outputId": "a17fbb6c-57b0-4977-ea84-44ab95992b69"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array[0] = 0.000000\n",
      "array[1] = 2.000000\n",
      "array[2] = 4.000000\n",
      "array[3] = 6.000000\n",
      "array[4] = 8.000000\n",
      "array[5] = 10.000000\n",
      "array[6] = 12.000000\n",
      "array[7] = 14.000000\n",
      "array[8] = 16.000000\n",
      "array[9] = 18.000000\n"
     ]
    }
   ],
   "source": [
    "# Simple example of parallelizing a loop with OpenMP\n",
    "# Save this C code to a file named \"simple_openmp.c\"\n",
    "\n",
    "simple_openmp = \"\"\"\n",
    "#include <omp.h>\n",
    "#include <stdio.h>\n",
    "\n",
    "void process_array(float *array, int size) {\n",
    "    #pragma omp parallel for\n",
    "    for (int i = 0; i < size; i++) {\n",
    "        array[i] = array[i] * 2.0;\n",
    "    }\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    int size = 1000;\n",
    "    float array[size];\n",
    "\n",
    "    // Initialize the array\n",
    "    for (int i = 0; i < size; i++) {\n",
    "        array[i] = i * 1.0;\n",
    "    }\n",
    "\n",
    "    process_array(array, size);\n",
    "\n",
    "    // Print the first 10 elements to verify\n",
    "    for (int i = 0; i < 10; i++) {\n",
    "        printf(\"array[%d] = %f\\\\n\", i, array[i]);\n",
    "    }\n",
    "\n",
    "    return 0;\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "# Write the OpenMP code to a file\n",
    "with open('simple_openmp.c', 'w') as f:\n",
    "    f.write(simple_openmp)\n",
    "\n",
    "# Compile the OpenMP C code using GCC with the -fopenmp flag\n",
    "!gcc -fopenmp -o simple_openmp simple_openmp.c\n",
    "\n",
    "# Run the compiled program\n",
    "!./simple_openmp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RDSK_fHYeKKz"
   },
   "source": [
    "# Exercise 7.2: OpenMP Directives and Clauses\n",
    "\n",
    "This exercise will guide you through the use of OpenMP directives and clauses, focusing on parallel regions, controlling the number of threads, and data sharing among threads.\n",
    "\n",
    "## 7.2.1 Parallel Regions\n",
    "A parallel region in OpenMP is a block of code that runs simultaneously across multiple threads. This is initiated using the `#pragma omp parallel` directive.\n",
    "\n",
    "### 7.2.1.1 num_threads Clause\n",
    "The `num_threads` clause specifies the exact number of threads to be used in the parallel region. This is important for optimizing performance and ensuring proper resource utilization.\n",
    "\n",
    "### 7.2.1.2 default Clause\n",
    "The `default` clause specifies the default data-sharing attributes for variables within a parallel region. It can be set to `shared`, `private`, or `none`, determining how variables are accessed by threads.\n",
    "\n",
    "## 7.2.2 Assigning the Number of Threads\n",
    "Assigning the number of threads can be done inside the code using the `num_threads` clause or outside the code using environment variables. Both methods have their own use cases and advantages.\n",
    "\n",
    "## 7.2.3 Work-sharing Constructs\n",
    "Work-sharing constructs in OpenMP, like `#pragma omp for` and `#pragma omp sections`, are used to divide tasks among threads, allowing for efficient parallel execution.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 305,
     "status": "ok",
     "timestamp": 1725225865734,
     "user": {
      "displayName": "Oscar Diez",
      "userId": "15296249123884043247"
     },
     "user_tz": -120
    },
    "id": "BtpdreA9eMor",
    "outputId": "ffb5c2f7-3658-4b00-83f6-ed0e412a3087"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of threads: 4\n",
      "Thread 0 is running\n",
      "Thread 3 is running\n",
      "Thread 2 is running\n",
      "Thread 1 is running\n"
     ]
    }
   ],
   "source": [
    "# Example of using OpenMP directives and clauses\n",
    "# Save this C code to a file named \"omp_directives.c\"\n",
    "\n",
    "omp_code = \"\"\"\n",
    "#include <omp.h>\n",
    "#include <stdio.h>\n",
    "\n",
    "int main() {\n",
    "    #pragma omp parallel num_threads(4)\n",
    "    {\n",
    "        int id = omp_get_thread_num();\n",
    "        int num_threads = omp_get_num_threads();\n",
    "        if (id == 0) {\n",
    "            printf(\"Total number of threads: %d\\\\n\", num_threads);\n",
    "        }\n",
    "        printf(\"Thread %d is running\\\\n\", id);\n",
    "    }\n",
    "    return 0;\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "# Write the OpenMP code to a file\n",
    "with open('omp_directives.c', 'w') as f:\n",
    "    f.write(omp_code)\n",
    "\n",
    "# Compile the OpenMP C code using GCC with the -fopenmp flag\n",
    "!gcc -fopenmp -o omp_directives omp_directives.c\n",
    "\n",
    "# Run the compiled program\n",
    "!./omp_directives\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QBiu65VXeO8b"
   },
   "source": [
    "# Exercise 7.3: Data Environment in OpenMP\n",
    "\n",
    "This exercise explores the data-sharing clauses in OpenMP, including `shared`, `private`, `firstprivate`, and `reduction`, which control how variables are accessed and modified within parallel regions.\n",
    "\n",
    "## 7.3.1 Data Sharing Clauses\n",
    "### 7.3.1.1 Shared Clause\n",
    "The `shared` clause makes a variable accessible to all threads in a parallel region, which can lead to race conditions if not synchronized properly.\n",
    "\n",
    "### 7.3.1.2 Private Clause\n",
    "The `private` clause ensures that each thread has its own instance of a variable, which is useful for thread-specific computations.\n",
    "\n",
    "### 7.3.1.3 Firstprivate Clause\n",
    "The `firstprivate` clause initializes private variables with the value from the master thread, ensuring consistent initial states across threads.\n",
    "\n",
    "## 7.3.2 Reduction Clause\n",
    "The `reduction` clause is used to perform a reduction operation (e.g., sum, product) on variables across all threads, combining their results into a single value.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 556,
     "status": "ok",
     "timestamp": 1725225914710,
     "user": {
      "displayName": "Oscar Diez",
      "userId": "15296249123884043247"
     },
     "user_tz": -120
    },
    "id": "09EWXueGeRCj",
    "outputId": "28acab8c-bd14-464a-ba65-676871ad38b4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Sum: 500500\n"
     ]
    }
   ],
   "source": [
    "# Example of using data-sharing clauses in OpenMP\n",
    "# Save this C code to a file named \"omp_data_clauses.c\"\n",
    "\n",
    "omp_data_code = \"\"\"\n",
    "#include <omp.h>\n",
    "#include <stdio.h>\n",
    "\n",
    "int main() {\n",
    "    int n = 1000;\n",
    "    int sum = 0;\n",
    "    int array[1000];\n",
    "\n",
    "    // Initialize the array\n",
    "    for (int i = 0; i < n; i++) {\n",
    "        array[i] = i + 1;\n",
    "    }\n",
    "\n",
    "    #pragma omp parallel for reduction(+:sum)\n",
    "    for (int i = 0; i < n; i++) {\n",
    "        sum += array[i];\n",
    "    }\n",
    "\n",
    "    printf(\"Total Sum: %d\\\\n\", sum); // Correct total sum\n",
    "    return 0;\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "# Write the OpenMP code to a file\n",
    "with open('omp_data_clauses.c', 'w') as f:\n",
    "    f.write(omp_data_code)\n",
    "\n",
    "# Compile the OpenMP C code using GCC with the -fopenmp flag\n",
    "!gcc -fopenmp -o omp_data_clauses omp_data_clauses.c\n",
    "\n",
    "# Run the compiled program\n",
    "!./omp_data_clauses\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SLhCRrUSebTN"
   },
   "source": [
    "# Exercise 7.4: Synchronization Techniques in OpenMP\n",
    "\n",
    "In this exercise, you will learn about synchronization techniques in OpenMP, including critical sections, atomic operations, barriers, and locks.\n",
    "\n",
    "## 7.4.1 Critical Sections\n",
    "A critical section is a block of code that must be executed by only one thread at a time, ensuring mutual exclusion.\n",
    "\n",
    "## 7.4.2 Atomic Operations\n",
    "Atomic operations provide a lightweight synchronization mechanism for simple updates to shared variables.\n",
    "\n",
    "## 7.4.3 Barrier Synchronization\n",
    "The `#pragma omp barrier` directive ensures that all threads reach a specific point before any can proceed, useful for coordinating tasks.\n",
    "\n",
    "## 7.4.4 Locks\n",
    "Locks provide fine-grained control over access to critical sections, allowing threads to acquire and release locks manually.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 285,
     "status": "ok",
     "timestamp": 1725225919735,
     "user": {
      "displayName": "Oscar Diez",
      "userId": "15296249123884043247"
     },
     "user_tz": -120
    },
    "id": "f728xresejPZ",
    "outputId": "85be59c1-c75c-447f-b762-cb7729e890dd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Balance: 1000\n"
     ]
    }
   ],
   "source": [
    "# Example of synchronization techniques in OpenMP\n",
    "# Save this C code to a file named \"omp_sync.c\"\n",
    "\n",
    "omp_sync_code = \"\"\"\n",
    "#include <omp.h>\n",
    "#include <stdio.h>\n",
    "\n",
    "int main() {\n",
    "    int balance = 0;\n",
    "    omp_lock_t lock;\n",
    "\n",
    "    omp_init_lock(&lock);\n",
    "\n",
    "    #pragma omp parallel for\n",
    "    for (int i = 0; i < 1000; i++) {\n",
    "        omp_set_lock(&lock);\n",
    "        balance += 1;\n",
    "        omp_unset_lock(&lock);\n",
    "    }\n",
    "\n",
    "    omp_destroy_lock(&lock);\n",
    "\n",
    "    printf(\"Final Balance: %d\\\\n\", balance);\n",
    "    return 0;\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "# Write the OpenMP code to a file\n",
    "with open('omp_sync.c', 'w') as f:\n",
    "    f.write(omp_sync_code)\n",
    "\n",
    "# Compile the OpenMP C code using GCC with the -fopenmp flag\n",
    "!gcc -fopenmp -o omp_sync omp_sync.c\n",
    "\n",
    "# Run the compiled program\n",
    "!./omp_sync\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 7.5: Scheduling and Load Balancing\n",
    "\n",
    "OpenMP can split loop iterations among threads using different *schedules*:\n",
    "- `static`: iterations are divided up front (low overhead; best when work is uniform).\n",
    "- `dynamic,chunk`: threads pull chunks as they finish (higher overhead; best when work is uneven).\n",
    "- `guided,chunk`: large chunks at first, shrinking over time (balance + lower overhead than dynamic).\n",
    "\n",
    "**Goal:** feel the difference by running the same irregular workload with different schedules.\n",
    "Tip: change `OMP_NUM_THREADS` to see effects.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "schedule(static)  : 0.590 s\n",
      "schedule(dynamic) : 0.545 s\n",
      "schedule(guided)  : 0.538 s\n"
     ]
    }
   ],
   "source": [
    "sched_code = r\"\"\"\n",
    "#include <omp.h>\n",
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "\n",
    "static inline double fake_work(int iters){\n",
    "    double x = 0.0;\n",
    "    for (int i=0;i<iters;i++) x += (i & 7) * 1e-8; // tiny flops to burn time\n",
    "    return x;\n",
    "}\n",
    "\n",
    "int main(){\n",
    "    const int N = 300000;                      // number of iterations\n",
    "    int *cost = (int*) malloc(N*sizeof(int));  // variable work per iteration\n",
    "    for (int i=0;i<N;i++) cost[i] = 50 + (i % 2000); // irregular cost\n",
    "\n",
    "    volatile double sink=0.0; // prevent optimizing out\n",
    "    double t0, t;\n",
    "\n",
    "    // static\n",
    "    t0 = omp_get_wtime();\n",
    "    #pragma omp parallel for schedule(static)\n",
    "    for (int i=0;i<N;i++) sink += fake_work(cost[i]);\n",
    "    t = omp_get_wtime() - t0;\n",
    "    printf(\"schedule(static)  : %.3f s\\n\", t);\n",
    "\n",
    "    // dynamic\n",
    "    t0 = omp_get_wtime();\n",
    "    #pragma omp parallel for schedule(dynamic,64)\n",
    "    for (int i=0;i<N;i++) sink += fake_work(cost[i]);\n",
    "    t = omp_get_wtime() - t0;\n",
    "    printf(\"schedule(dynamic) : %.3f s\\n\", t);\n",
    "\n",
    "    // guided\n",
    "    t0 = omp_get_wtime();\n",
    "    #pragma omp parallel for schedule(guided,64)\n",
    "    for (int i=0;i<N;i++) sink += fake_work(cost[i]);\n",
    "    t = omp_get_wtime() - t0;\n",
    "    printf(\"schedule(guided)  : %.3f s\\n\", t);\n",
    "\n",
    "    free(cost);\n",
    "    return 0;\n",
    "}\n",
    "\"\"\"\n",
    "open(\"omp_schedule.c\",\"w\").write(sched_code)\n",
    "!gcc -O2 -fopenmp -o omp_schedule omp_schedule.c\n",
    "!OMP_NUM_THREADS=4 ./omp_schedule\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 7.6: Data Races and Synchronization Choices\n",
    "\n",
    "We'll intentionally create a race condition and then fix it in three ways:\n",
    "1) `critical` (safest but heaviest),\n",
    "2) `atomic` (lightweight for simple updates),\n",
    "3) `reduction` (fastest for associative ops like sums).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No sync         : c=1000000 (expected 1000000)  0.0001 s\n",
      "critical        : c=1000000               0.0233 s\n",
      "atomic          : c=1000000               0.0075 s\n",
      "reduction (sum) : c=1000000               0.0000 s\n"
     ]
    }
   ],
   "source": [
    "race_code = r\"\"\"\n",
    "#include <omp.h>\n",
    "#include <stdio.h>\n",
    "\n",
    "int main(){\n",
    "    const int N = 1000000;\n",
    "    long long c;\n",
    "\n",
    "    double t0, t;\n",
    "\n",
    "    // 1) No synchronization (race!)\n",
    "    c = 0;\n",
    "    t0 = omp_get_wtime();\n",
    "    #pragma omp parallel for\n",
    "    for (int i=0;i<N;i++) c += 1;   // DATA RACE\n",
    "    t = omp_get_wtime() - t0;\n",
    "    printf(\"No sync         : c=%lld (expected %d)  %.4f s\\n\", c, N, t);\n",
    "\n",
    "    // 2) critical\n",
    "    c = 0;\n",
    "    t0 = omp_get_wtime();\n",
    "    #pragma omp parallel for\n",
    "    for (int i=0;i<N;i++){\n",
    "        #pragma omp critical\n",
    "        c += 1;\n",
    "    }\n",
    "    t = omp_get_wtime() - t0;\n",
    "    printf(\"critical        : c=%lld               %.4f s\\n\", c, t);\n",
    "\n",
    "    // 3) atomic\n",
    "    c = 0;\n",
    "    t0 = omp_get_wtime();\n",
    "    #pragma omp parallel for\n",
    "    for (int i=0;i<N;i++){\n",
    "        #pragma omp atomic\n",
    "        c += 1;\n",
    "    }\n",
    "    t = omp_get_wtime() - t0;\n",
    "    printf(\"atomic          : c=%lld               %.4f s\\n\", c, t);\n",
    "\n",
    "    // 4) reduction\n",
    "    c = 0;\n",
    "    t0 = omp_get_wtime();\n",
    "    #pragma omp parallel for reduction(+:c)\n",
    "    for (int i=0;i<N;i++) c += 1;\n",
    "    t = omp_get_wtime() - t0;\n",
    "    printf(\"reduction (sum) : c=%lld               %.4f s\\n\", c, t);\n",
    "\n",
    "    return 0;\n",
    "}\n",
    "\"\"\"\n",
    "open(\"omp_race.c\",\"w\").write(race_code)\n",
    "!gcc -O2 -fopenmp -o omp_race omp_race.c\n",
    "!OMP_NUM_THREADS=4 ./omp_race\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 7.7: Task Parallelism\n",
    "\n",
    "OpenMP tasks let you express irregular or recursive parallelism.\n",
    "Here we compute `fib(n)` with tasks (for teaching only; not efficient). Key ideas:\n",
    "- Create tasks inside a `single` region.\n",
    "- Use `taskwait` to join child tasks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fib(30) = 832040  (time 0.003 s)\n"
     ]
    }
   ],
   "source": [
    "tasks_code = r\"\"\"\n",
    "#include <omp.h>\n",
    "#include <stdio.h>\n",
    "\n",
    "long long fib_seq(int n){ return (n<=1) ? n : fib_seq(n-1)+fib_seq(n-2); }\n",
    "\n",
    "long long fib_task(int n){\n",
    "    if (n < 20) return fib_seq(n); // cutoff to limit task overhead\n",
    "    long long x=0, y=0;\n",
    "    #pragma omp task shared(x)\n",
    "    x = fib_task(n-1);\n",
    "    #pragma omp task shared(y)\n",
    "    y = fib_task(n-2);\n",
    "    #pragma omp taskwait\n",
    "    return x + y;\n",
    "}\n",
    "\n",
    "int main(){\n",
    "    int n = 30;\n",
    "    long long r=0;\n",
    "    double t0 = omp_get_wtime();\n",
    "    #pragma omp parallel\n",
    "    {\n",
    "        #pragma omp single\n",
    "        r = fib_task(n);\n",
    "    }\n",
    "    double t = omp_get_wtime() - t0;\n",
    "    printf(\"fib(%d) = %lld  (time %.3f s)\\n\", n, r, t);\n",
    "    return 0;\n",
    "}\n",
    "\"\"\"\n",
    "open(\"omp_tasks.c\",\"w\").write(tasks_code)\n",
    "!gcc -O2 -fopenmp -o omp_tasks omp_tasks.c\n",
    "!OMP_NUM_THREADS=4 ./omp_tasks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 7.8: `collapse` for 2D Loops (Matrix Multiply)\n",
    "\n",
    "`collapse(2)` flattens the `i,j` loops so OpenMP can distribute more work across threads.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C[0,0]=400.0  time=0.012 s  (threads=4)\n"
     ]
    }
   ],
   "source": [
    "mm_code = r\"\"\"\n",
    "#include <omp.h>\n",
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "\n",
    "int main(){\n",
    "    const int N = 200; // keep modest so it runs fast in class\n",
    "    double *A = (double*) malloc(N*N*sizeof(double));\n",
    "    double *B = (double*) malloc(N*N*sizeof(double));\n",
    "    double *C = (double*) malloc(N*N*sizeof(double));\n",
    "\n",
    "    for (int i=0;i<N*N;i++){ A[i]=1.0; B[i]=2.0; C[i]=0.0; }\n",
    "\n",
    "    double t0 = omp_get_wtime();\n",
    "    #pragma omp parallel for collapse(2)\n",
    "    for (int i=0;i<N;i++){\n",
    "        for (int j=0;j<N;j++){\n",
    "            double s = 0.0;\n",
    "            for (int k=0;k<N;k++){\n",
    "                s += A[i*N+k]*B[k*N+j];\n",
    "            }\n",
    "            C[i*N+j] = s;\n",
    "        }\n",
    "    }\n",
    "    double t = omp_get_wtime() - t0;\n",
    "\n",
    "    printf(\"C[0,0]=%.1f  time=%.3f s  (threads=%d)\\n\", C[0], t, omp_get_max_threads());\n",
    "\n",
    "    free(A); free(B); free(C);\n",
    "    return 0;\n",
    "}\n",
    "\"\"\"\n",
    "open(\"omp_collapse.c\",\"w\").write(mm_code)\n",
    "!gcc -O3 -fopenmp -o omp_collapse omp_collapse.c\n",
    "!OMP_NUM_THREADS=4 ./omp_collapse\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 7.9: `sections` and `nowait`\n",
    "\n",
    "Use `sections` to run unrelated work in parallel without a loop.\n",
    "Add `nowait` on a preceding `for` to remove the implicit barrier and overlap work.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min=0  max=999999  sum=499999500000\n"
     ]
    }
   ],
   "source": [
    "sections_code = r\"\"\"\n",
    "#include <omp.h>\n",
    "#include <stdio.h>\n",
    "#include <limits.h>\n",
    "\n",
    "int main(){\n",
    "    const int N = 1000000;\n",
    "    int minv = INT_MAX, maxv = INT_MIN;\n",
    "    long long sum = 0;\n",
    "\n",
    "    // Fill a simple sequence and do three different reductions in parallel sections\n",
    "    #pragma omp parallel\n",
    "    {\n",
    "        #pragma omp sections\n",
    "        {\n",
    "            #pragma omp section\n",
    "            {\n",
    "                int local_min = INT_MAX;\n",
    "                for (int i=0;i<N;i++){ if (i<local_min) local_min=i; }\n",
    "                #pragma omp critical\n",
    "                if (local_min < minv) minv = local_min;\n",
    "            }\n",
    "            #pragma omp section\n",
    "            {\n",
    "                int local_max = INT_MIN;\n",
    "                for (int i=0;i<N;i++){ if (i>local_max) local_max=i; }\n",
    "                #pragma omp critical\n",
    "                if (local_max > maxv) maxv = local_max;\n",
    "            }\n",
    "            #pragma omp section\n",
    "            {\n",
    "                long long local_sum = 0;\n",
    "                for (int i=0;i<N;i++) local_sum += i;\n",
    "                #pragma omp atomic\n",
    "                sum += local_sum;\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    printf(\"min=%d  max=%d  sum=%lld\\n\", minv, maxv, sum);\n",
    "    return 0;\n",
    "}\n",
    "\"\"\"\n",
    "open(\"omp_sections.c\",\"w\").write(sections_code)\n",
    "!gcc -O2 -fopenmp -o omp_sections omp_sections.c\n",
    "!OMP_NUM_THREADS=4 ./omp_sections\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 7.10: SIMD Vectorization\n",
    "\n",
    "`#pragma omp simd` tells the compiler to vectorize the loop. Combine with a reduction to keep it correct.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dot=8388608.0  time=0.002 s\n"
     ]
    }
   ],
   "source": [
    "simd_code = r\"\"\"\n",
    "#include <omp.h>\n",
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "\n",
    "int main(){\n",
    "    const int N = 1<<22; // ~4 million\n",
    "    float *a = (float*) aligned_alloc(64, N*sizeof(float));\n",
    "    float *b = (float*) aligned_alloc(64, N*sizeof(float));\n",
    "    for (int i=0;i<N;i++){ a[i]=1.0f; b[i]=2.0f; }\n",
    "\n",
    "    double t0 = omp_get_wtime();\n",
    "    float dot = 0.0f;\n",
    "    #pragma omp simd reduction(+:dot)\n",
    "    for (int i=0;i<N;i++) dot += a[i]*b[i];\n",
    "    double t = omp_get_wtime() - t0;\n",
    "\n",
    "    printf(\"dot=%.1f  time=%.3f s\\n\", dot, t);\n",
    "    free(a); free(b);\n",
    "    return 0;\n",
    "}\n",
    "\"\"\"\n",
    "open(\"omp_simd.c\",\"w\").write(simd_code)\n",
    "!gcc -O3 -march=native -fopenmp -o omp_simd omp_simd.c\n",
    "!./omp_simd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional: OpenMP 6.0 Event Dependencies (Preview)\n",
    "\n",
    "OpenMP 6.0 introduces event-style dependencies to coordinate CPU tasks with asynchronous device work.\n",
    "Concept: a GPU `target` operation produces an *event*; tasks that `depend(in:event)` will wait for it without a global barrier.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved omp60_event_demo.c (compile only if your compiler supports OpenMP 6.0).\n"
     ]
    }
   ],
   "source": [
    "open(\"omp60_event_demo.c\",\"w\").write(r\"\"\"\n",
    "// Requires OpenMP 6.0+ compiler with offloading support\n",
    "#include <omp.h>\n",
    "#include <stdio.h>\n",
    "int main(){\n",
    "    const int N=1000;\n",
    "    double A[N], B[N];\n",
    "    for (int i=0;i<N;i++){ A[i]=i; B[i]=0; }\n",
    "\n",
    "    omp_event_handle_t ev;\n",
    "    #pragma omp target nowait depend(out: ev) map(to: A[0:N]) map(from: B[0:N])\n",
    "    for (int i=0;i<N;i++) B[i] = 2.0*A[i];\n",
    "\n",
    "    #pragma omp task depend(in: ev)\n",
    "    printf(\"B[10]=%.1f (should be 20.0)\\n\", B[10]);\n",
    "\n",
    "    #pragma omp taskwait\n",
    "    return 0;\n",
    "}\n",
    "\"\"\")\n",
    "print(\"Saved omp60_event_demo.c (compile only if your compiler supports OpenMP 6.0).\")\n",
    "# Example compile line (adjust for your platform/back-end):\n",
    "# !clang -fopenmp -fopenmp-targets=nvptx64 -O2 omp60_event_demo.c -o omp60_event_demo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 7.X: Real HPC Mini-App — 2-D Heat Diffusion (Jacobi Stencil)\n",
    "\n",
    "**Context.** Many HPC codes solve PDEs (e.g., heat equation) with iterative *stencil* updates over a grid.\n",
    "At each iteration (sweep), every interior cell becomes the average of its four neighbors — a classic **5-point Jacobi** update.\n",
    "\n",
    "We’ll implement:\n",
    "1. **Serial Jacobi** (baseline)\n",
    "2. **OpenMP Jacobi** using `#pragma omp parallel for collapse(2)`\n",
    "\n",
    "We keep fixed boundary conditions (Dirichlet): left boundary = 1, others = 0.  \n",
    "We compare runtimes and verify that both versions produce (nearly) identical results.\n",
    "\n",
    "**What to watch:**\n",
    "- `collapse(2)` exposes more parallelism across the 2-D loop nest.\n",
    "- Speedup depends on problem size, memory bandwidth, and `OMP_NUM_THREADS`.\n",
    "- This kernel is memory-bound; expect good but not linear speedups.\n",
    "\n",
    "*Try:* change `N`, `ITERS`, and `OMP_NUM_THREADS` to see the effect.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Run with 1 thread (baseline OpenMP path still compiled, but serial time is separate) ---\n",
      "Jacobi 2D: N=1024, ITERS=200, OMP_MAX_THREADS=1\n",
      "Time serial : 0.159 s\n",
      "Time OpenMP : 0.641 s\n",
      "Speedup     : 0.25x\n",
      "Max |diff|  : 0.000e+00\n",
      "Center value: serial=0.000000  omp=0.000000\n",
      "\n",
      "--- Run with 8 threads (adjust to your machine) ---\n",
      "Jacobi 2D: N=1024, ITERS=200, OMP_MAX_THREADS=8\n",
      "Time serial : 0.169 s\n",
      "Time OpenMP : 0.680 s\n",
      "Speedup     : 0.25x\n",
      "Max |diff|  : 0.000e+00\n",
      "Center value: serial=0.000000  omp=0.000000\n"
     ]
    }
   ],
   "source": [
    "jacobi_c = r\"\"\"\n",
    "#include <omp.h>\n",
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "#include <string.h>\n",
    "#include <math.h>\n",
    "\n",
    "#define IDX(i,j,N) ((i)*(N) + (j))\n",
    "\n",
    "static void* xmalloc_aligned(size_t nbytes){\n",
    "    void *p = NULL;\n",
    "    #if defined(_POSIX_C_SOURCE) && _POSIX_C_SOURCE >= 200112L\n",
    "    if (posix_memalign(&p, 64, nbytes) != 0) p = NULL;\n",
    "    #else\n",
    "    p = aligned_alloc(64, ((nbytes + 63)/64)*64);\n",
    "    #endif\n",
    "    if (!p){ fprintf(stderr, \"Allocation failed\\n\"); exit(1); }\n",
    "    return p;\n",
    "}\n",
    "\n",
    "static void init_bc(double *A, int N){\n",
    "    // Zero everywhere\n",
    "    for (int i=0;i<N*N;i++) A[i]=0.0;\n",
    "    // Left boundary to 1.0\n",
    "    for (int i=0;i<N;i++) A[IDX(i,0,N)] = 1.0;\n",
    "}\n",
    "\n",
    "static double* jacobi_serial(double *A, double *B, int N, int iters){\n",
    "    for (int it=0; it<iters; ++it){\n",
    "        for (int i=1;i<N-1;i++){\n",
    "            for (int j=1;j<N-1;j++){\n",
    "                B[IDX(i,j,N)] = 0.25 * (A[IDX(i-1,j,N)] + A[IDX(i+1,j,N)]\n",
    "                                      + A[IDX(i,j-1,N)] + A[IDX(i,j+1,N)]);\n",
    "            }\n",
    "        }\n",
    "        // swap\n",
    "        double *tmp = A; A = B; B = tmp;\n",
    "    }\n",
    "    return (iters % 2 == 0) ? A : B;\n",
    "}\n",
    "\n",
    "static double* jacobi_omp(double *A, double *B, int N, int iters){\n",
    "    for (int it=0; it<iters; ++it){\n",
    "        #pragma omp parallel for collapse(2) schedule(static)\n",
    "        for (int i=1;i<N-1;i++){\n",
    "            for (int j=1;j<N-1;j++){\n",
    "                B[IDX(i,j,N)] = 0.25 * (A[IDX(i-1,j,N)] + A[IDX(i+1,j,N)]\n",
    "                                      + A[IDX(i,j-1,N)] + A[IDX(i,j+1,N)]);\n",
    "            }\n",
    "        }\n",
    "        // implicit barrier at end of parallel for\n",
    "        double *tmp = A; A = B; B = tmp;\n",
    "    }\n",
    "    return (iters % 2 == 0) ? A : B;\n",
    "}\n",
    "\n",
    "static double max_abs_diff(const double *X, const double *Y, int N){\n",
    "    double m = 0.0;\n",
    "    for (int i=0;i<N*N;i++){\n",
    "        double d = fabs(X[i]-Y[i]);\n",
    "        if (d > m) m = d;\n",
    "    }\n",
    "    return m;\n",
    "}\n",
    "\n",
    "int main(int argc, char **argv){\n",
    "    int N = (argc > 1) ? atoi(argv[1]) : 1024; // grid size (NxN)\n",
    "    int ITERS = (argc > 2) ? atoi(argv[2]) : 200;\n",
    "\n",
    "    printf(\"Jacobi 2D: N=%d, ITERS=%d, OMP_MAX_THREADS=%d\\n\",\n",
    "           N, ITERS, omp_get_max_threads());\n",
    "\n",
    "    size_t bytes = (size_t)N * (size_t)N * sizeof(double);\n",
    "\n",
    "    // Serial copies\n",
    "    double *A1 = (double*) xmalloc_aligned(bytes);\n",
    "    double *B1 = (double*) xmalloc_aligned(bytes);\n",
    "    init_bc(A1, N); memset(B1, 0, bytes);\n",
    "\n",
    "    // Parallel copies\n",
    "    double *A2 = (double*) xmalloc_aligned(bytes);\n",
    "    double *B2 = (double*) xmalloc_aligned(bytes);\n",
    "    init_bc(A2, N); memset(B2, 0, bytes);\n",
    "\n",
    "    // --- Serial ---\n",
    "    double t0 = omp_get_wtime();\n",
    "    double *R1 = jacobi_serial(A1, B1, N, ITERS);\n",
    "    double t_serial = omp_get_wtime() - t0;\n",
    "\n",
    "    // --- OpenMP ---\n",
    "    t0 = omp_get_wtime();\n",
    "    double *R2 = jacobi_omp(A2, B2, N, ITERS);\n",
    "    double t_omp = omp_get_wtime() - t0;\n",
    "\n",
    "    // Validate\n",
    "    double diff = max_abs_diff(R1, R2, N);\n",
    "\n",
    "    printf(\"Time serial : %.3f s\\n\", t_serial);\n",
    "    printf(\"Time OpenMP : %.3f s\\n\", t_omp);\n",
    "    if (t_omp > 0.0) printf(\"Speedup     : %.2fx\\n\", t_serial / t_omp);\n",
    "    printf(\"Max |diff|  : %.3e\\n\", diff);\n",
    "\n",
    "    // Print a representative interior value\n",
    "    int ci = N/2, cj = N/2;\n",
    "    printf(\"Center value: serial=%.6f  omp=%.6f\\n\",\n",
    "           R1[IDX(ci,cj,N)], R2[IDX(ci,cj,N)]);\n",
    "\n",
    "    free(A1); free(B1); free(A2); free(B2);\n",
    "    return 0;\n",
    "}\n",
    "\"\"\"\n",
    "open(\"omp_jacobi.c\",\"w\").write(jacobi_c)\n",
    "!gcc -O3 -march=native -fopenmp -o omp_jacobi omp_jacobi.c\n",
    "\n",
    "# Run once with a small-ish grid and a few threads; tweak as you like.\n",
    "print(\"\\n--- Run with 1 thread (baseline OpenMP path still compiled, but serial time is separate) ---\")\n",
    "!OMP_NUM_THREADS=1 ./omp_jacobi 1024 200\n",
    "\n",
    "print(\"\\n--- Run with 8 threads (adjust to your machine) ---\")\n",
    "!OMP_NUM_THREADS=8 ./omp_jacobi 1024 200\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNZV3xrcRtMsTgmAnN0Q58z",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
